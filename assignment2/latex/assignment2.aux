\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Dependencies in a Directed Graphical Model}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}In the graphical model of Figure 1, is $W_{d, n} \perp W_{d,n+1} \mid \theta _{d}, \beta _{1:K}$?}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}In the graphical model of Figure 1, is $ \theta _{d} \perp \theta _{d+1} \mid Z_{d, 1:N}$?}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}In the graphical model of Figure 1, is $ \theta _{d} \perp \theta _{d+1} \mid \alpha , Z_{1:D, 1:N}$?}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}In the graphical model of Figure 2, is $ W_{d, n} \perp W_{d,n+1} \mid \Lambda _{d}, \beta _{1:K} $?}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}In the graphical model of Figure 2, is $ \theta _{d} \perp \theta _{d+1} \mid Z_{d, 1:N}, Z_{d+1, 1:N}$?}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}In the graphical model of Figure 2, is $ \Lambda _{d} \perp \Lambda _{d + 1} \mid \Phi , Z_{1:D, 1:n}$?}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Likelihood of a Tree Graphical Model}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Implement a dynamic programming algorithm that for a given $T, \Theta , \beta $ computes $p(\beta \mid T, \Theta )$}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Report $p(\beta \mid T, \Theta )$ for each given data}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Small tree}{3}{}\protected@file@percent }
\citation{book}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Medium tree}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Large tree}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Super Epicentra - Expectation-Maximization}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Derive an EM algorithm for the model}{4}{}\protected@file@percent }
\citation{book}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Implement your EM algorithm}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Apply it to the data provided, give an account of the success and provide visualizations for a couple examples. Repeat it for a few different choices of K.}{6}{}\protected@file@percent }
\citation{book}
\@writefile{toc}{\contentsline {section}{\numberline {4}Appendix}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Appendix 1}{17}{}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{../code/task\textunderscore 2\textunderscore 2/q2\textunderscore 2.py}{17}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Appendix 2}{20}{}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{../code/task\textunderscore 2\textunderscore 4/expectation\textunderscore maximization.py}{20}{}\protected@file@percent }
\bibdata{citations}
\bibcite{book}{1}
\bibstyle{plain}
\gdef \@abspage@last{23}
